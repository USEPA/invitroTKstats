---
title: "Data Guide Creation and Level-0 Data Compilation"
output: rmarkdown::html_vignette
vignette: >
  %\VignetteIndexEntry{data_guide_and_LO}
  %\VignetteEngine{knitr::rmarkdown}
  %\VignetteEncoding{UTF-8}
---

```{r, include = FALSE}
knitr::opts_chunk$set(
  collapse = TRUE,
  comment = "#>"
)
```

# Overview

The `invitroTKstats` R package is designed to work as a data processing pipeline for *in vitro* assays collecting various physiological parameters used in high-throughput toxicokinetic (HTTK) modeling.  This pipeline is meant to take mass spectrometry (MS) data to estimate the various physiological parameters.

Here, we discuss the first steps of the data processing pipeline, which include creating the data guide and compliation of level-0 (raw) data. *Note, these steps are meant to be consistent across the various assays that may be pipelined by this package, i.e. not assay specific.*

## Suggested packages for use with this vignette

```{r setup}
# Primary Packages #
library(invitroTKstats)
# Data Formatting Packages #
library(dplyr)
library(magrittr)
library(stringr)
```

# Data Catalog Creation

The data catalog creation step can be thought of as a log of all the relevant raw data files for a given physiological parameter that we wish to pipeline.  It is a crucial part of the pipeline in that it allows us to identify where all of the raw datafiles are coming from and where we are pulling raw (Level-0) data from within those datasets.  This provides key meta-data information that can be used for evaluating data provenance.

Though this `data.frame` may be created manually through an Excel file, the `invitroTKstats` package includes a function called `create_data_catalog` that will automatically generate and document the creation of the data catalog.  This allows for maximum reproducibility, transparency, and efficiency in compiling the necessary data guide/catalog.  Thus, it is a best practice to utilize this function for creating the data file.

*NOTE: The terms "data catalog" and "data guide" are used interchangeably throughout the vignette.*

Below is an example of how to use this function

```{r eval=FALSE}
### DO NOT EVALUATE THIS CODE CHUNK ###
# create a data catalog listing where Fup data is held
DC <- create_catalog(
  # file path(s) -> file name(s): "<file_path>/my_raw_MS_data_Clint_MMDDYYYY.xlsx"
  file = "<file_path>/my_raw_MS_data_Clint_MMDDYYYY.xlsx",
  # sheet name/number
  sheet = c(rep(1,5),rep(2,5),rep(3,5)),
  # number of rows in Excel file to skip
  skip.rows = rep(c(1,10,19,28,37),3),
  # number of rows to read in may be the same and/or different
  num.rows = 8,
  # date with 2-digt month, 2-digit day, and 4-digit year
  date = "MMDDYYYY"
  )
```

We are going to construct a data guide for the Kruetz et al. (2023) PFAS Cl~int~ Data.

```{r}
DC_kreutz.pfas <- create_catalog(
  # filename (no file path)
  file = c(rep("Hep_745_949_959_082421_final.xlsx",3)), 
  # sheet name (or sheet number)
  sheet = c(rep("Data063021",3)), 
  # number of rows to skip in L0 Excel file - start for compound/analyte samples
  skip.rows = c(43,73,91), 
  # number of rows to read in from L0 Excel file for compound/analyte samples
  num.rows = c(30,17,109), 
  # date the data was generated
  #   (MMDDYYY: 2-digit month, 2-digit day, 4-digit year)
  date = "06302021", 
  # chemical id
  compound = c("745","949","959"),
  # internal standard compound (corresponding to chemical id)
  istd = c("MFBET","MFHET","MFOET"),
  # column name for sample names
  sample = "Name", 
  # column name for sample types
  type = "Type",
  # column name(s) for analyte MS peak areas
  peak = c("Area...13","Area...20","Area...27"),
  # column name(s) for internal standard MS peak areas
  istd.peak = c("Resp....16","Resp....23","Resp....30"),
  # column name(s) for experimental concentration
  conc = c("Final Conc....11","Final Conc....11","Final Conc....11"),
  # column name(s) with analysis parameters
  analysis.param = c("Exp. Conc....10","Exp. Conc....17","Exp. Conc....24")
  # note = "RT...12"
)
```

Show the constructed data guide/catalog for the Kreutz PFAS Cl~int~ data.

```{r}
DC_kreutz.pfas
```

# Merge Level-0 (L0) Data

Now that we have a data guide we want to pull in all of the 'raw' level-0 data.

**********RETURN HERE**********

```{r raw_data_path,echo=TRUE}
raw_data_path <- "~/Git/invitrotkstats/working/KreutzPFAS"
```

```{r chem_id_table}
# obtain the chemical identification mapping information from the MS-data
#   cover sheet (i.e. raw data summary information)
assay_cover_sheet <-
  readxl::read_xlsx(
    paste(raw_data_path,"Hep_745_949_959_082421_final.xlsx",sep = "/"),
    sheet = "Cover Sheet",skip = 35,n_max = 4) %>% 
  as.data.frame()

# show the assay cover sheet
assay_cover_sheet

# create a chemical table necessary for the L0 compilation function, using the
#   assay cover sheet chemical identification mapping information
chem.ids <- create_chem_table(
  # input table (data.frame class) with information
  input.table = assay_cover_sheet,
  # column name with DSSTox chemical ID's
  dtxsid.col = "Analyte",
  # column name with formal compound names
  compound.col = "Name",
  # column name with lab chemical ID's
  lab.compound.col = "Sample ID"
)

# show the chemical ID mapping data
chem.ids
```

```{r}
kreutz.pfas_L0 <- merge_level0(
  level0.catalog = DC_kreutz.pfas, # data catalog
  INPUT.DIR = raw_data_path, # the path to your raw data files
  istd.col = "ISTD.Name",
  type.colname.col = "Type.ColName",
  chem.ids = chem.ids, # chemical ID mapping data
  chem.lab.id.col = "Lab.Compound.Name",
  chem.name.col = "Compound.Name",
  catalog.out = FALSE, # do not export the data catalog during this function
  output.res = FALSE # do not export the compiled L0 during this function
) # hitting a browser statement - this will need to be fixed in 'dev' first
```


# Best Practices for Data Processing

* The data catalog can be manually constructed as done in this markdown. This is the minimum expectation.  However, the best practice would be to create a wrapper function for your particular Mass-Spectrometry data to leverage the `create_catalog` function, but to auto-generate the input for this function programmatically (e.g. a lab-specific processing function).
* Users may manually construct data catalogs in Excel files, this is not recommended but may occur in cases of working with legacy data (i.e. data processed prior to 2025).  In this scenario, it is recommended to use the `check_catalog` to ensure the data catalog meets the minimum meta-data reporting requirements to use `merge_level0`.
